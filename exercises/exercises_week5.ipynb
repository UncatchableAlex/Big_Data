{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: Machine Learning 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T15:30:03.634114Z",
     "start_time": "2017-08-23T15:30:03.629294Z"
    }
   },
   "source": [
    "There are myriad machine learning models (and algorithms for fitting them to data) out there, and each one has something special about it that makes it suitable to a specific type of problem. To apply machine learning and get some initial results is fairly straight forward. Getting under the hood, however, requires a bit of work. This week we focus on how Decision Trees work. In the exercises today you will:\n",
    "\n",
    "* Implement a standard decision tree mechanism\n",
    "* Play around with a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before you do anything else**:\n",
    "\n",
    "Load the `pandas.DataFrame` containing team alliances for each character that you created last week, e.g. into a variable called `data_teams`. You will use this in the exercises below. I refer to this data specifically when I mention the \"data\".\n",
    "\n",
    "*Note:* We are working with all three factions again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>#Fearsome Four</th>\n",
       "      <th>1991 in comics</th>\n",
       "      <th>2013 in comics</th>\n",
       "      <th>A-Force</th>\n",
       "      <th>A-Next</th>\n",
       "      <th>A.I. Army</th>\n",
       "      <th>A.R.M.O.R.</th>\n",
       "      <th>Acolytes (comics)</th>\n",
       "      <th>Action Pack (comics)</th>\n",
       "      <th>...</th>\n",
       "      <th>Xavier Institute student body</th>\n",
       "      <th>Xavier's Security Enforcers</th>\n",
       "      <th>Yakuza</th>\n",
       "      <th>Young Allies</th>\n",
       "      <th>Young Allies (Marvel Comics)</th>\n",
       "      <th>Young Avengers</th>\n",
       "      <th>Young Masters</th>\n",
       "      <th>Young X-Men</th>\n",
       "      <th>Zodiac (comics)</th>\n",
       "      <th>faction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abner Jenkins</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abomination (character)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abraham Cornelius</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Absorbing Man</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adam Warlock</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>Yellowjacket (Marvel Comics)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>Yo-Yo Rodriguez</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>Zeke Stane</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>Zheng Zu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>Zzzax</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>697 rows Ã— 436 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Unnamed: 0  #Fearsome Four  1991 in comics  \\\n",
       "0                   Abner Jenkins               0               0   \n",
       "1         Abomination (character)               0               0   \n",
       "2               Abraham Cornelius               0               0   \n",
       "3                   Absorbing Man               0               0   \n",
       "4                    Adam Warlock               0               0   \n",
       "..                            ...             ...             ...   \n",
       "692  Yellowjacket (Marvel Comics)               0               0   \n",
       "693               Yo-Yo Rodriguez               0               0   \n",
       "694                    Zeke Stane               0               0   \n",
       "695                      Zheng Zu               0               0   \n",
       "696                         Zzzax               0               0   \n",
       "\n",
       "     2013 in comics  A-Force  A-Next  A.I. Army  A.R.M.O.R.  \\\n",
       "0                 0        0       0          0           0   \n",
       "1                 0        0       0          0           0   \n",
       "2                 0        0       0          0           0   \n",
       "3                 0        0       0          0           0   \n",
       "4                 0        0       0          0           0   \n",
       "..              ...      ...     ...        ...         ...   \n",
       "692               0        0       0          0           0   \n",
       "693               0        0       0          0           0   \n",
       "694               0        0       0          0           0   \n",
       "695               0        0       0          0           0   \n",
       "696               0        0       0          0           0   \n",
       "\n",
       "     Acolytes (comics)  Action Pack (comics)  ...  \\\n",
       "0                    0                     0  ...   \n",
       "1                    0                     0  ...   \n",
       "2                    0                     0  ...   \n",
       "3                    0                     0  ...   \n",
       "4                    0                     0  ...   \n",
       "..                 ...                   ...  ...   \n",
       "692                  0                     0  ...   \n",
       "693                  0                     0  ...   \n",
       "694                  0                     0  ...   \n",
       "695                  0                     0  ...   \n",
       "696                  0                     0  ...   \n",
       "\n",
       "     Xavier Institute student body  Xavier's Security Enforcers  Yakuza  \\\n",
       "0                                0                            0       0   \n",
       "1                                0                            0       0   \n",
       "2                                0                            0       0   \n",
       "3                                0                            0       0   \n",
       "4                                0                            0       0   \n",
       "..                             ...                          ...     ...   \n",
       "692                              0                            0       0   \n",
       "693                              0                            0       0   \n",
       "694                              0                            0       0   \n",
       "695                              0                            0       0   \n",
       "696                              0                            0       0   \n",
       "\n",
       "     Young Allies  Young Allies (Marvel Comics)  Young Avengers  \\\n",
       "0               0                             0               0   \n",
       "1               0                             0               0   \n",
       "2               0                             0               0   \n",
       "3               0                             0               0   \n",
       "4               0                             0               0   \n",
       "..            ...                           ...             ...   \n",
       "692             0                             0               0   \n",
       "693             0                             0               0   \n",
       "694             0                             0               0   \n",
       "695             0                             0               0   \n",
       "696             0                             0               0   \n",
       "\n",
       "     Young Masters  Young X-Men  Zodiac (comics)  faction  \n",
       "0                0            0                0        2  \n",
       "1                0            0                0        1  \n",
       "2                0            0                0        0  \n",
       "3                0            0                0        0  \n",
       "4                0            0                0        1  \n",
       "..             ...          ...              ...      ...  \n",
       "692              0            0                0        2  \n",
       "693              0            0                0        1  \n",
       "694              0            0                0        0  \n",
       "695              0            0                0        0  \n",
       "696              0            0                0        0  \n",
       "\n",
       "[697 rows x 436 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../outputs/marvel_characters.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part 1 you will implement the decision making algorithm of a decision tree classifier, step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T14:01:10.834257Z",
     "start_time": "2017-08-23T14:01:10.826472Z"
    }
   },
   "source": [
    ">**Ex. 5.1.1**: Read about [Shannon entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)).\n",
    "1. What is it? How is it defined mathematically (write out the formula in LateX formatting)?\n",
    "2. Write a function that computes the Shannon-entropy of a probability vector. Compute the Shannon entropy of `p=[0.2, 0.3, 0.5]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1.1.1: Shannon entropy is the average amount of information contained in knowing the state of a point in a dataset. Shannon entropy is defined mathematically as $$H(X) = - \\sum_{x \\in \\Omega} p(x)\\log p(x)$$\n",
    "where $X$ is a discrete random variable distributed across $p: \\Omega \\rightarrow [0, 1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4854752972273344"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def shannon(prob_vec):\n",
    "    return -sum(0 if prob == 0 else prob * math.log(prob, 2) for prob in prob_vec)\n",
    "\n",
    "shannon([0.2, 0.3, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T14:01:10.834257Z",
     "start_time": "2017-08-23T14:01:10.826472Z"
    }
   },
   "source": [
    ">**Ex. 5.1.2**: Split your data (`data_teams`) into two subsets. One where characters are affiliated with X-men and one where they are not.\n",
    "1. What is the entropy of target labels in each subset?\n",
    "2. What is the weighted average entropy of the split?\n",
    "3. Write a function that computes the weighted average entropy of a split, given the data and team (name or id) on which to split the data. Show that it gives you the same split entropy that you obtained in point 2.\n",
    "4. Plot the distribution of split entropy for all features. Comment on the result. My figure looks [like this](https://dhsvendsen.github.io/images/BD_5_1_2_4.png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The X-Men have a shannon entropy of 1.2189514568588302 and the non-X-Men have a shannon_entropy of 1.4113733977368847'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.1.2.1\n",
    "xman = df.loc[(df['X-Men'] == 1)]\n",
    "non_xman = df.loc[(df['X-Men'] != 1)]\n",
    "# get the proportion of each faction in the xman dataframe\n",
    "xman_prob_vec = [len(xman.loc[(xman['faction'] == faction)]) / len(xman) for faction in range(0, 3)]\n",
    "non_xman_prob_vec = [len(non_xman.loc[(non_xman['faction'] == faction)]) / len(non_xman) for faction in range(0, 3)]\n",
    "f'The X-Men have a shannon entropy of {shannon(xman_prob_vec)} and the non-X-Men have a shannon_entropy of {shannon(non_xman_prob_vec)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4025391048988678"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.1.2.2\n",
    "weighted_average_across_xman_split = ((shannon(xman_prob_vec) * len(xman)) + (shannon(non_xman_prob_vec) * len(non_xman))) / (len(xman) + len(non_xman))\n",
    "weighted_average_across_xman_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4025391048988678"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.1.2.3\n",
    "def avg_weighted_shannon_across_split(df, split, entropy_feature, possible_entropy_feature_values):\n",
    "    a = df.loc[(df[split] == 1)]\n",
    "    b = df.loc[(df[split] != 1)]\n",
    "    if (len(a) == 0 or len(b) == 0):\n",
    "        print(split)\n",
    "    a_vec = [len(a.loc[(a[entropy_feature] == feat)]) / len(a) for feat in possible_entropy_feature_values]\n",
    "    b_vec = [len(b.loc[(b[entropy_feature] == feat)]) / len(b) for feat in possible_entropy_feature_values]\n",
    "    try:\n",
    "        return ((shannon(a_vec) * len(a)) + (shannon(b_vec) * len(b))) / (len(a) + len(b))\n",
    "    except:\n",
    "        print(f'{a_vec} {b_vec} {split}')\n",
    "\n",
    "avg_weighted_shannon_across_split(df, 'X-Men', 'faction', range(0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2.,   1.,   1.,   1.,   2.,   6.,   8.,  24.,  80., 309.]),\n",
       " array([1.37670094, 1.38147561, 1.38625027, 1.39102493, 1.3957996 ,\n",
       "        1.40057426, 1.40534893, 1.41012359, 1.41489826, 1.41967292,\n",
       "        1.42444758]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5.1.2.4\n",
    "from matplotlib import pyplot as plt\n",
    "split_entropies = [avg_weighted_shannon_across_split(df, col, 'faction', range(0, 3)) for col in df.columns.values[1:-1]]\n",
    "plt.hist(split_entropies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T14:01:10.834257Z",
     "start_time": "2017-08-23T14:01:10.826472Z"
    }
   },
   "source": [
    ">**Ex. 5.1.EXTRA**: Print the maximum entropy path of a decision tree. Before you start, make a copy of `data_teams` called `data`.\n",
    ">\n",
    ">1. Implement the following pseudocode and print the output:<br><br>\n",
    ">Step 1. Find `team` that gives lowest split entropy for `data`. Print `team`.<br>\n",
    ">Step 2. Split `data` on `team`, to produce `data0` and `data1`. Print the entropy of each, as well as the weighted avg. entropy.<br>\n",
    ">Step 3. Overwrite the `data` variable with either `data0` or `data1`, depending on which has the highest entropy.<br>\n",
    ">Step 4. Stop if there are less than 5 datapoints in `data`. Otherwise start over from 1.<br><br>\n",
    ">My output looks [like this](https://dhsvendsen.github.io/images/BD_5_1_1.png) for the first five splits.<br><br>\n",
    ">\n",
    ">2. Comment on decision path your code takes: How many splits are there? Do you notice anything interesting about the final splits?\n",
    ">3. Train a `sklearn.tree.DecisionTreeClassifier` classifier on the dataset. Initiate the classifier with `criterion='entropy'`. What are the most important features of this classifier? How does this line up with the order of splits you just printed (a comment is fine)?\n",
    ">\n",
    "> **Will not be included in the assignment. Worth up to 10 extra credit.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regressions are great baseline models for comparing how well a more complicated model works.\n",
    "They are literally just linear regressions where the output is *squeezed* through a `sigmoid` function,\n",
    "so the returned value is between 0 and 1 (which can be interpreted as a probability if one so desired)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T14:01:10.834257Z",
     "start_time": "2017-08-23T14:01:10.826472Z"
    }
   },
   "source": [
    ">**Ex. 5.2.1**: Implement a logistic regression model.\n",
    "Below I have implemented a *linear* regression model which takes *two* input parameter.\n",
    "Create another function, `logistic_regression` that takes again two input\n",
    "variables and returns a value between 0 and 1. Demonstrate that it works by inputting\n",
    "the data, `x=[1, 1]`, and parameters, `w0=1`, `w1=1` and `w2=0`, below, and show that it gives 0.88.\n",
    ">\n",
    ">*Hint*: The `sigmoid` function can look like this:\n",
    ">\n",
    ">        def sigmoid(x):\n",
    ">            return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30636\\2409085221.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mw0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mw1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mw2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mlinear_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def linear_regression(x, w0, w1, w2):\n",
    "    return x[:,0]*w0 + x[:,1]*w1 + w2\n",
    "\n",
    "# example\n",
    "x = np.array([[1, 1]])\n",
    "w0 = -1; w1 = 2; w2 = -2\n",
    "linear_regression(x, w0, w1, w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The function below generates some 2d data with labels. Show that the current parameter values (`w0 = -1; w1 = 2; w2 = -2`) of the `logistic_regression` function you wrote are not optimal by plotting `x[:, 0]` vs. `x[:, 1]` and colouring the points according to their predicted output-values (y's). I.e. setting `c=predictions` in the scatterplot. My figure looks like [this](https://dhsvendsen.github.io/images/BD_5_2_2_a.png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T20:03:52.954182Z",
     "start_time": "2020-01-10T20:03:52.948047Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "\n",
    "def generate_X_linear(N=200):\n",
    "    \"\"\"A little function that creates some data.\"\"\"\n",
    "    x = np.vstack([\n",
    "        np.random.normal([-1.5, -1.5], 1, size=(int(N/2), 2)),\n",
    "        np.random.normal([1.5, 1.5], 1, size=(int(N/2), 2))\n",
    "    ])\n",
    "\n",
    "    y = np.array([0] * int(N/2) + [1] * int(N/2))\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "# Generate input and output data\n",
    "x, y = generate_X_linear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot and color by actual class-label\n",
    "plt.scatter(x[:,0], x[:,1], c=y)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T14:01:10.834257Z",
     "start_time": "2017-08-23T14:01:10.826472Z"
    }
   },
   "source": [
    ">**Ex. 5.2.2**: *Fit* a logistic regression! You can use the `scipy` module `scipy.optimize.curve_fit`\n",
    "to fit a model to some data (i.e. find the best parameter values `w`). \n",
    "> Fit the `logistic_regression` to the data `x` (input) and `y` (target).\n",
    "> Again, plot and color the points according to their prediction. My figure looks like [this](https://dhsvendsen.github.io/images/BD_5_2_2_b.png). Comment on the figure and on the shape of the decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 (extra): Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These days, neural networks are probably the hottest item in machine learning, and for good reason. Neural networks *can* be a bit of a mouthful to understand, and since I didn't talk about them in this course much (if at all), you can solve this problem if you have sufficient interest for it. That said, it is a skill well worth investing in.\n",
    "\n",
    "We will be using the deep learning library **PyTorch** to build some neural networks with which we can play around with. *Nerdnote: Why not something more high-level such as Keras with a Tensorflow backend? Well PyTorch is easier to install. And using it, it's clearer what actually happens when you fit a neural network. Finally, for those taking the ANN course it's good to see something new.*\n",
    "\n",
    "To get torch running you need to first install it. It's should be fairly straight forward, but depending on\n",
    "your machine you may have to run different commands to install it. Check out the installation guide [here](https://pytorch.org/).\n",
    "\n",
    "Once you've installed it you should be able to go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T20:11:01.452132Z",
     "start_time": "2020-01-10T20:11:00.948643Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No errors? Great! Then let's make a small neural network that we know all to well at this point, and see if we can classify points with it. First, we generate some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T20:11:08.210033Z",
     "start_time": "2020-01-10T20:11:08.180133Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_X_nonlinear(N=200, R=5):\n",
    "\n",
    "    X_inner = torch.randn(int(N/2), 2)\n",
    "\n",
    "    X_outer = torch.tensor([\n",
    "        [R*np.cos(theta), R*np.sin(theta)]\n",
    "        for theta in np.linspace(0, 2 * np.pi, int(N/2))\n",
    "    ]) + torch.randn(int(N/2), 2)\n",
    "\n",
    "    X = torch.cat([X_inner, X_outer], dim=0)\n",
    "   \n",
    "    y = torch.cat([\n",
    "        torch.zeros(int(N/2)).reshape(-1, 1),\n",
    "        torch.ones(int(N/2)).reshape(-1, 1)\n",
    "    ])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Number of training datapoints\n",
    "N = 500\n",
    "\n",
    "# Generate the data (note that code is using torch arrays now)\n",
    "x, y = generate_X_nonlinear(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this data, we can now set up a neural network and train it. We are not going to do anything fancy here, just make a simple 2-layer feed forward neural network with 2 input neurons, 3 hidden neurons and 1 output neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T20:11:10.492454Z",
     "start_time": "2020-01-10T20:11:10.489791Z"
    }
   },
   "outputs": [],
   "source": [
    "# The layers and their number of neurons\n",
    "sizes = [2, 3, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to define the model. PyTorch has an API called `Sequential` that makes this pretty easy. Try to get an idea of what the below code is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T20:11:13.559775Z",
     "start_time": "2020-01-10T20:11:13.554596Z"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(sizes[0], sizes[1]),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(sizes[1], sizes[2]),\n",
    "    torch.nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we need to define a loss function. We are just going to use the sum of squared errors, and again PyTorch has got an implementation we can pick right off the shelf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T20:11:35.908984Z",
     "start_time": "2020-01-10T20:11:35.905765Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can just train it! We pick a learning rate parameter (which is how big the steps we take during\n",
    "gradient descent are), define an *optimizer* which is a wrapper for training that abstracts away all the\n",
    "usual steps. The `epochs` are simply the number of times we train on the entire dataset. Then we are ready to\n",
    "train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T20:11:40.927457Z",
     "start_time": "2020-01-10T20:11:40.626962Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "learning_rate = 1e-1\n",
    "epochs = 100\n",
    "mini_batch_size = 100\n",
    "\n",
    "# Optimization wrapper\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train\n",
    "for t in range(epochs):\n",
    "    \n",
    "    # Randomly permute the row indices to get something like:\n",
    "    # tensor([16214, 18491, 16308,  ..., 19629, 17565, 24696])\n",
    "    permutation = torch.randperm(x.size()[0])\n",
    "    \n",
    "    # Start looping over the mini-batches! Each index `k` is\n",
    "    # `mini_batch_size` values apart.\n",
    "    for k in np.arange(0, x.size()[0], mini_batch_size):\n",
    "        \n",
    "        # Extract mini-batch data. The rest is the same\n",
    "        mini_batch_indices = permutation[k:k+mini_batch_size]\n",
    "        x_ = x[mini_batch_indices, :]\n",
    "        y_ = y[mini_batch_indices, :]\n",
    "        \n",
    "        # Forward pass\n",
    "        y_pred = model(x_)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(y_pred, y_)\n",
    "\n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable\n",
    "        # weights of the model). This is because by default, gradients are\n",
    "        # accumulated in buffers (i.e, not overwritten) whenever .backward()\n",
    "        # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    # Print progress (here evaluating on all the data so we can compare)\n",
    "    if t % 10 == 0:\n",
    "        loss = loss_fn(model(x), y)\n",
    "        print(t, \"train:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the errors we are showing here are the sum of squared errors. You'd have to jump through a small hoop (which is very doable) to get the accuracy. Also, this is the error on the training data. So there's no guarantee that we don't overfit here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can visualize the predictions next to the true labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T20:11:48.642842Z",
     "start_time": "2020-01-10T20:11:48.634096Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "class cmap_in_range:\n",
    "    \"\"\"Create map to range of colors inside given domain.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> cmap = cmap_in_range([0, 1])\n",
    "    >>> cmap(0.1)\n",
    "    (0.30392156862745101, 0.30315267411304353, 0.98816547208125938, 1.0)\n",
    "    \"\"\"\n",
    "    def __init__(self, cmap_domain, cmap_range=[0, 1], cmap_style='rainbow'):\n",
    "        self.cmap_domain = cmap_domain\n",
    "        self.cmap_range = cmap_range\n",
    "        self.m = interp1d(cmap_domain, cmap_range)\n",
    "        self.cmap = plt.get_cmap(cmap_style)\n",
    "        \n",
    "    def __call__(self, value):\n",
    "        if not self.cmap_domain[0] <= value <= self.cmap_domain[1]:\n",
    "            raise Exception(\"Value must be inside cmap_domain.\")\n",
    "        return self.cmap(self.m(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T20:11:51.223029Z",
     "start_time": "2020-01-10T20:11:50.753343Z"
    }
   },
   "outputs": [],
   "source": [
    "cmap = cmap_in_range([0, 1])\n",
    "\n",
    "y_true = y.reshape(-1).numpy()\n",
    "y_pred = model(x).data.numpy().reshape(-1)\n",
    "\n",
    "plt.figure(figsize=(9, 3))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"True\", fontsize=12)\n",
    "plt.scatter(x[:, 0], x[:, 1], color=list(map(cmap, y_true)))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Predicted\", fontsize=12)\n",
    "plt.scatter(x[:, 0], x[:, 1], color=list(map(cmap, y_pred)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Alright. Your turn..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 5.3.EXTRA**: Can you fit a neural network like the above (maybe with more or less layers and different number of hidden neurons in each layer) to the marvel data to predict good vs. evil?\n",
    "* Make a random 80/20 split of the data for training and testing.\n",
    "* Train only on the 80% and report an accuracy on the 20%.\n",
    "* Comment on the result. Is it better than what you can obtain using a Random Forest classifier on the same training and test split?\n",
    ">\n",
    "> **Will not be included in the assignment. Worth up to 5 extra credit.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
